{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c5b43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f84f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('../style/style-formal.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd810095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 projects: ['Lang', 'Mockito', 'Math', 'Time', 'Chart']\n",
      "Individual project results will be saved to respective directories\n",
      "Combined results will be saved to: /ssd_home/yangheechan/d4j_research_data/attempt_1/combined_experiment_results\n"
     ]
    }
   ],
   "source": [
    "RESEARCH_DATA = os.environ.get(\"RESEARCH_DATA\")\n",
    "\n",
    "EL = \"attempt_1\"\n",
    "PIDS = [\"Lang\", \"Mockito\", \"Math\", \"Time\", \"Chart\"]\n",
    "\n",
    "SBFL_FORMULA = [\n",
    "    \"tarantula\", \"ochiai\", \"dstar\",\n",
    "    \"naish1\", \"naish2\", \"gp13\"\n",
    "]\n",
    "\n",
    "TRANSITION_TYPES = {\n",
    "    \"type1\": \"result_transition\",\n",
    "    \"type2\": \"exception_type_transition\",\n",
    "    \"type3\": \"exception_msg_transition\",\n",
    "    \"type4\": \"stacktrace_transition\",\n",
    "    \"type5\": \"all_types_transition\"\n",
    "}\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "root_dir = os.path.dirname(curr_dir)\n",
    "dot_exp_config_file = os.path.join(root_dir, \".experiment_config-rq3\")\n",
    "EXP_CONFIG = json.load(open(dot_exp_config_file, \"r\"))\n",
    "\n",
    "LINE_CNT = EXP_CONFIG[\"target_lines\"][-1]\n",
    "MUT_CNT = EXP_CONFIG[\"mutation_cnt\"][-1]\n",
    "TCS_REDUCTION = EXP_CONFIG[\"tcs_reduction\"]\n",
    "TCS_EXP_LIST = [\"All\"]\n",
    "\n",
    "if len(EXP_CONFIG[\"target_lines\"]) > 1:\n",
    "    EXPERIMENT_TYPE = \"lineCnt\"\n",
    "elif len(EXP_CONFIG[\"mutation_cnt\"]) > 1:\n",
    "    EXPERIMENT_TYPE = \"mutCnt\"\n",
    "else:\n",
    "    EXPERIMENT_TYPE = \"tcsReduction\"\n",
    "    TCS_EXP_LIST.append(\"Reduced\")\n",
    "\n",
    "TOP_N = [1, 3, 5, 10]\n",
    "\n",
    "# Create output directories for each PID and a combined results directory\n",
    "PID_OUT_DIRS = {}\n",
    "for PID in PIDS:\n",
    "    # PID_OUT_DIR = os.path.join(RESEARCH_DATA, EL, f\"{PID}-v1\", \"experiment_information_results\")\n",
    "    PID_OUT_DIR = os.path.join(RESEARCH_DATA, EL, f\"{PID}\", \"experiment_information_results\")\n",
    "    if not os.path.exists(PID_OUT_DIR):\n",
    "        os.makedirs(PID_OUT_DIR, exist_ok=True)\n",
    "    PID_OUT_DIRS[PID] = PID_OUT_DIR\n",
    "\n",
    "# Create a combined results directory\n",
    "COMBINED_OUT_DIR = os.path.join(RESEARCH_DATA, EL, \"combined_experiment_results\")\n",
    "if not os.path.exists(COMBINED_OUT_DIR):\n",
    "    os.makedirs(COMBINED_OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Processing {len(PIDS)} projects: {PIDS}\")\n",
    "print(f\"Individual project results will be saved to respective directories\")\n",
    "print(f\"Combined results will be saved to: {COMBINED_OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9033da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to upper one level so that I can import lib.database\n",
    "os.chdir(os.path.dirname(curr_dir))\n",
    "from lib.database import CRUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84b3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sbfl_execution_time():\n",
    "    # Initiate CRUD\n",
    "    db = CRUD(\n",
    "        host=os.environ.get(\"DB_HOST\"),\n",
    "        port=os.environ.get(\"DB_PORT\"),\n",
    "        user=os.environ.get(\"DB_USER\"),\n",
    "        password=os.environ.get(\"DB_PASSWORD\"),\n",
    "        database=os.environ.get(\"DB_NAME\"),\n",
    "        slack_channel=os.environ.get(\"SLACK_CHANNEL\"),\n",
    "        slack_token=os.environ.get(\"SLACK_TOKEN\"),\n",
    "    )\n",
    "\n",
    "    sbfl_time = {}\n",
    "    for pid in PIDS:\n",
    "        sbfl_time[pid] = {}\n",
    "        fault_info_res = db.read(\n",
    "            \"d4j_fault_info\",\n",
    "            columns=\"fault_idx, bug_id\",\n",
    "            conditions={\n",
    "                \"project\": pid,\n",
    "                \"experiment_label\": EL,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for fault_idx, bug_id in fault_info_res:\n",
    "            sbfl_time[pid][bug_id] = {}\n",
    "            tc_info_res = db.read(\n",
    "                \"d4j_tc_info\",\n",
    "                columns=\"tc_idx, result, execution_time_ms\",\n",
    "                conditions={\n",
    "                    \"fault_idx\": fault_idx,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            for tc_idx, result, execution_time_ms in tc_info_res:\n",
    "                sbfl_time[pid][bug_id][tc_idx] = execution_time_ms\n",
    "    \n",
    "    # with open(\"exec_ms\", \"w\") as f:\n",
    "    #     json.dump(sbfl_time, f, indent=4)\n",
    "\n",
    "    sbfl_total_time_ms = 0\n",
    "    for pid, bug_data in sbfl_time.items():\n",
    "        for bug_id, tc_data in bug_data.items():\n",
    "            for tc_idx, exec_time in tc_data.items():\n",
    "                sbfl_total_time_ms += exec_time\n",
    "    \n",
    "    db.__del__()\n",
    "    return sbfl_total_time_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2450bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_time_per_method(pid, bid, rid, lineIdx2lineData, mbfl_time):\n",
    "    if EXPERIMENT_TYPE == \"lineCnt\":\n",
    "        exp_list = EXP_CONFIG[\"target_lines\"]\n",
    "    elif EXPERIMENT_TYPE == \"mutCnt\":\n",
    "        exp_list = EXP_CONFIG[\"mutation_cnt\"]\n",
    "    elif EXPERIMENT_TYPE == \"tcsReduction\":\n",
    "        exp_list = TCS_EXP_LIST\n",
    "\n",
    "    for exp_cnt in exp_list:\n",
    "        if EXPERIMENT_TYPE == \"lineCnt\":\n",
    "            time_key = f\"lineCnt{exp_cnt}_mutCnt{MUT_CNT}_tcs{TCS_REDUCTION}_result_transition_total_execution_time_ms\"\n",
    "        elif EXPERIMENT_TYPE == \"mutCnt\":\n",
    "            time_key = f\"lineCnt{LINE_CNT}_mutCnt{exp_cnt}_tcs{TCS_REDUCTION}_result_transition_total_execution_time_ms\"\n",
    "        elif EXPERIMENT_TYPE == \"tcsReduction\":\n",
    "            time_key = f\"lineCnt{LINE_CNT}_mutCnt{MUT_CNT}_tcs{exp_cnt}_result_transition_total_execution_time_ms\"\n",
    "\n",
    "        # Get first_data in lineIdx2lineData\n",
    "        first_data = next(iter(lineIdx2lineData.values()))\n",
    "        total_execution_time_ms = first_data[time_key]\n",
    "        # # WARNING WILL BE REMOVED AFTER CONSTRUCTING THE DATA AGAIN\n",
    "        # first_data = {}\n",
    "        # total_execution_time_ms = -1\n",
    "        # for key, data in lineIdx2lineData.items():\n",
    "        #     if time_key in data.keys():\n",
    "        #         total_execution_time_ms = data[time_key]\n",
    "\n",
    "        # if total_execution_time_ms == -1:\n",
    "        #     time_key = time_key.replace(\"type1\", \"result_transition\")\n",
    "        #     # print(f\"Warning: No execution time found for {pid}, {bid}, {rid}, {time_key}. Setting to -1.\")\n",
    "\n",
    "        # first_data = {}\n",
    "        # total_execution_time_ms = -1\n",
    "        # for key, data in lineIdx2lineData.items():\n",
    "        #     if time_key in data.keys():\n",
    "        #         total_execution_time_ms = data[time_key]\n",
    "        \n",
    "        # if total_execution_time_ms == -1:\n",
    "        #     # print(f\"Warning: No execution time found for {pid}, {bid}, {rid}, {time_key}. Setting to -1.\")\n",
    "        #     raise ValueError(f\"No execution time found for {pid}, {bid}, {rid}, {time_key}. Please check the data.\")\n",
    "\n",
    "\n",
    "        if time_key not in mbfl_time:\n",
    "            mbfl_time[time_key] = {}\n",
    "        \n",
    "        if pid not in mbfl_time[time_key]:\n",
    "            mbfl_time[time_key][pid] = {}\n",
    "        \n",
    "        if bid not in mbfl_time[time_key][pid]:\n",
    "            mbfl_time[time_key][pid][bid] = {}\n",
    "        \n",
    "        if rid not in mbfl_time[time_key][pid][bid]:\n",
    "            mbfl_time[time_key][pid][bid][rid] = {}\n",
    "\n",
    "        # total_execution_time_ms = first_data[time_key]\n",
    "        mbfl_time[time_key][pid][bid][rid] = total_execution_time_ms\n",
    "\n",
    "def measure_mbfl_execution_time():\n",
    "    mbfl_time = {}\n",
    "\n",
    "    for pid in PIDS:\n",
    "        for rid in range(1, EXP_CONFIG[\"num_repeats\"]+1):\n",
    "            RID_DIR_NAME = f\"repeat_{rid}\"\n",
    "            # RID_DIR = os.path.join(RESEARCH_DATA, EL, f\"{pid}-v1\", \"experiment_raw_results\", RID_DIR_NAME)\n",
    "            RID_DIR = os.path.join(RESEARCH_DATA, EL, f\"{pid}\", \"experiment_raw_results\", RID_DIR_NAME)\n",
    "\n",
    "            for bid_res_file in os.listdir(RID_DIR):\n",
    "                pck_file = os.path.join(RID_DIR, bid_res_file)\n",
    "                with open(pck_file, \"rb\") as f:\n",
    "                    bid = int(bid_res_file.split(\"_\")[0])\n",
    "\n",
    "                    lineIdx2lineData = pickle.load(f)\n",
    "                    record_time_per_method(pid, bid, RID_DIR_NAME, lineIdx2lineData, mbfl_time)\n",
    "    \n",
    "    # Measure the average for each repeat across each bugs\n",
    "    # and measure the total execution time ms\n",
    "    # for each method\n",
    "    method2time = {}\n",
    "    for method, pid_data in mbfl_time.items():\n",
    "        method2time[method] = []\n",
    "\n",
    "        pid_total = 0\n",
    "        for pid, bid_data in pid_data.items():\n",
    "            bid_total = 0\n",
    "            for bid, rid_data in bid_data.items():\n",
    "                rid_time_list = []\n",
    "                for rid, exec_time in rid_data.items():\n",
    "                    rid_time_list.append(exec_time)\n",
    "                bid_total += sum(rid_time_list) / len(rid_time_list)\n",
    "            pid_total += bid_total\n",
    "        method2time[method].append(pid_total)\n",
    "    \n",
    "    for method, times in method2time.items():\n",
    "        total_time = sum(times)\n",
    "        print(f\"Method: {method}, Total Execution Time: {total_time} ms\")\n",
    "        \n",
    "            \n",
    "\n",
    "    with open(\"mbfl_exec_ms.json\", \"w\") as f:\n",
    "        json.dump(mbfl_time, f, indent=4)\n",
    "\n",
    "    return method2time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d161b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_dlfl_execution_time():\n",
    "    if EXPERIMENT_TYPE == \"lineCnt\":\n",
    "        exp_list = EXP_CONFIG[\"target_lines\"]\n",
    "    elif EXPERIMENT_TYPE == \"mutCnt\":\n",
    "        exp_list = EXP_CONFIG[\"mutation_cnt\"]\n",
    "    elif EXPERIMENT_TYPE == \"tcsReduction\":\n",
    "        exp_list = TCS_EXP_LIST\n",
    "    \n",
    "    dlfl_time = {}\n",
    "    for exp_cnt in exp_list:\n",
    "        if EXPERIMENT_TYPE == \"lineCnt\":\n",
    "            method_key = f\"lineCnt{exp_cnt}_mutCnt{MUT_CNT}_tcs{TCS_REDUCTION}\"\n",
    "        elif EXPERIMENT_TYPE == \"mutCnt\":\n",
    "            method_key = f\"lineCnt{LINE_CNT}_mutCnt{exp_cnt}_tcs{TCS_REDUCTION}\"\n",
    "        elif EXPERIMENT_TYPE == \"tcsReduction\":\n",
    "            method_key = f\"lineCnt{LINE_CNT}_mutCnt{MUT_CNT}_tcs{exp_cnt}\"\n",
    "\n",
    "        if method_key not in dlfl_time:\n",
    "            dlfl_time[method_key] = {}\n",
    "\n",
    "        for rid in range(1, EXP_CONFIG[\"num_repeats\"]+1):\n",
    "            RID_DIR_NAME = f\"repeat_{rid}\"\n",
    "            # final_results_json = os.path.join(RESEARCH_DATA, EL, \"dlfl_out-v1/experiment_raw_results\", RID_DIR_NAME, \"methods\", method_key, \"final_results.json\")\n",
    "            final_results_json = os.path.join(RESEARCH_DATA, EL, \"dlfl_out/experiment_raw_results\", RID_DIR_NAME, \"methods\", method_key, \"final_results.json\")\n",
    "\n",
    "            if RID_DIR_NAME not in dlfl_time[method_key]:\n",
    "                dlfl_time[method_key][RID_DIR_NAME] = {}\n",
    "            \n",
    "            results_data = json.load(open(final_results_json, \"r\"))\n",
    "            time_secs = results_data[\"total\"][\"train_time_seconds\"]\n",
    "            dlfl_time[method_key][RID_DIR_NAME] = time_secs\n",
    "    \n",
    "    # Measure the average for each repeat across each bugs\n",
    "    # and measure the total execution time ms\n",
    "    method2time = {}\n",
    "    for method, rid_data in dlfl_time.items():\n",
    "        method2time[method] = []\n",
    "\n",
    "        rid_total = 0\n",
    "        for rid, exec_time in rid_data.items():\n",
    "            rid_total += exec_time\n",
    "        method2time[method].append(rid_total)\n",
    "\n",
    "    for method, times in method2time.items():\n",
    "        total_time = sum(times)\n",
    "        print(f\"Method: {method}, Total Execution Time: {total_time} seconds\")\n",
    "\n",
    "    return method2time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d1cd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv_time(sbfl_total_time_ms, mbfl_time, dlfl_time):\n",
    "    methods2time = {}\n",
    "    for method, time in dlfl_time.items():\n",
    "        methods2time[method] = {\n",
    "            \"sbfl\": sbfl_total_time_ms/1000,\n",
    "            \"mbfl\": 0,\n",
    "            \"dlfl\": sum(time)\n",
    "        }\n",
    "\n",
    "        for key, mbfl_data in mbfl_time.items():\n",
    "            if method in key and sum(mbfl_data) != 0:\n",
    "                methods2time[method][\"mbfl\"] = sum(mbfl_data)/1000\n",
    "\n",
    "        methods2time[method][\"total_seconds\"] = methods2time[method][\"sbfl\"] + methods2time[method][\"mbfl\"] + methods2time[method][\"dlfl\"]\n",
    "        methods2time[method][\"total_minutes\"] = methods2time[method][\"total_seconds\"] / 60\n",
    "        methods2time[method][\"total_hours\"] = methods2time[method][\"total_minutes\"] / 60\n",
    "\n",
    "    df = pd.DataFrame.from_dict(methods2time, orient='index')\n",
    "    df = df.reset_index().rename(columns={\"index\": \"method\"})\n",
    "    df = df[[\"method\", \"sbfl\", \"mbfl\", \"dlfl\", \"total_seconds\", \"total_minutes\", \"total_hours\"]]\n",
    "    df.to_csv(os.path.join(COMBINED_OUT_DIR, f\"execution_time_summary-{EXPERIMENT_TYPE}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "158a8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SBFL execution time: 548777.340402993 ms\n"
     ]
    }
   ],
   "source": [
    "# 1. Measure SBFL execution time\n",
    "sbfl_total_time_ms = measure_sbfl_execution_time()\n",
    "print(f\"Total SBFL execution time: {sbfl_total_time_ms} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8343ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: lineCnt70_mutCnt7_tcsAll_result_transition_total_execution_time_ms, Total Execution Time: 1050136324.1384995 ms\n",
      "Method: lineCnt70_mutCnt7_tcsReduced_result_transition_total_execution_time_ms, Total Execution Time: 404624208.2690169 ms\n"
     ]
    }
   ],
   "source": [
    "# 2. Measure MBFL execution time (average across repeats)\n",
    "method2mbfltime = measure_mbfl_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2406b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: lineCnt70_mutCnt7_tcsAll, Total Execution Time: 1573.4424171447754 seconds\n",
      "Method: lineCnt70_mutCnt7_tcsReduced, Total Execution Time: 1511.7837388515472 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3. Measure DLFL execution time (average across repeats)\n",
    "method2dlfltime = measure_dlfl_execution_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0ca869",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_csv_time(sbfl_total_time_ms, method2mbfltime, method2dlfltime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fee1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
